{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00c93139-9d75-4fb5-a248-368ffd9b2356",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Celeste\\AppData\\Roaming\\nltk_data...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41cb6901-1154-4e1e-aa42-4c65a3ceb444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Description  Quantity       Date  UnitPrice  CustomerID  Total Amount  \\\n",
      "0         NaN         1 2023-12-26       50.0        25.0          50.0   \n",
      "1         NaN         2 2023-03-22      500.0       161.0        1000.0   \n",
      "2         NaN         1 2023-10-18       25.0       191.0          25.0   \n",
      "3         NaN         3 2023-09-22       30.0       218.0          90.0   \n",
      "4         NaN         1 2023-03-03      500.0       220.0         500.0   \n",
      "\n",
      "   Gender  Age Product Category  \n",
      "0  Female   64           Beauty  \n",
      "1    Male   64           Beauty  \n",
      "2    Male   64           Beauty  \n",
      "3    Male   64           Beauty  \n",
      "4    Male   64           Beauty  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel(r\"C:\\Users\\Celeste\\OneDrive\\Documents\\Target_customer_dataV1.xlsx\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c0483b-2a64-4b6a-962a-840653f6a3b5",
   "metadata": {},
   "source": [
    "#### Deriving a product category from descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "658253fc-b070-4908-ae8d-8b2335c3c624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate rows with and without a Product Category\n",
    "df['Product Category'] = df['Product Category'].fillna('')  # Fill NaN with empty string for easier processing\n",
    "\n",
    "# Replace NaN values with an empty string for vectorizer\n",
    "df['Description'] = df['Description'].fillna('No description available')\n",
    "\n",
    "# Identify rows where 'Product Category' is missing (empty string)\n",
    "missing_data = df['Product Category'] == ''\n",
    "\n",
    "# Data with known Product Categories (used for training)\n",
    "train_data = df[~missing_data]\n",
    "\n",
    "# Data with missing Product Categories (used for prediction)\n",
    "predict_data = df[missing_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0417430f-2d61-4e09-961d-b05f58673d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "# Initialize the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Function to clean and preprocess text\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # Lowercase\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)  # Remove non-alphabet characters\n",
    "    text = \" \".join([lemmatizer.lemmatize(word) for word in text.split()])  # Lemmatize words\n",
    "    return text\n",
    "\n",
    "# Apply the cleaning function to the 'Description' column\n",
    "df['Description'] = df['Description'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b0212ec-85a5-4c0d-a6b0-1f00c4467a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the features (X) and target (y) for training\n",
    "X_train = train_data['Description']  # Descriptions to train on\n",
    "y_train = train_data['Product Category']  # Corresponding Product Categories\n",
    "\n",
    "# Vectorize the descriptions\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_df=0.9, min_df=3)\n",
    "X = vectorizer.fit_transform(df['Description'])\n",
    "y = df['Product Category']\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Get the number of unique classes\n",
    "n_classes = len(np.unique(y_train))\n",
    "\n",
    "# Set uniform priors (each class gets an equal probability)\n",
    "uniform_priors = np.full(n_classes, 1/n_classes)\n",
    "\n",
    "# Initialize the model with uniform priors\n",
    "model = MultinomialNB(class_prior=uniform_priors)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c0c0df60-7057-4be4-aa80-49a0705a808c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.52%\n"
     ]
    }
   ],
   "source": [
    "# Check accuracy\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d11ed7a-0baa-4114-bebb-9b6ce999b4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the missing Product Categories\n",
    "X_predict = predict_data['Description']  # Descriptions to predict\n",
    "X_predict_tfidf = vectorizer.transform(X_predict)  # Apply the same vectorizer to the predict data\n",
    "\n",
    "# Make predictions for the missing data\n",
    "predicted_categories = model.predict(X_predict_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "488fcbce-e0a1-4e6c-a7eb-1afb7ff4a00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Description Product Category\n",
      "0   no description available           Beauty\n",
      "1   no description available           Beauty\n",
      "2   no description available           Beauty\n",
      "3   no description available           Beauty\n",
      "4   no description available           Beauty\n",
      "5   no description available           Beauty\n",
      "6   no description available           Beauty\n",
      "7   no description available           Beauty\n",
      "8   no description available           Beauty\n",
      "9   no description available           Beauty\n",
      "10  no description available         Clothing\n",
      "11  no description available         Clothing\n",
      "12  no description available         Clothing\n",
      "13  no description available         Clothing\n",
      "14  no description available         Clothing\n",
      "15  no description available         Clothing\n",
      "16  no description available         Clothing\n",
      "17  no description available         Clothing\n",
      "18  no description available         Clothing\n",
      "19  no description available         Clothing\n"
     ]
    }
   ],
   "source": [
    "# Update the 'Product Category' column with the predicted values\n",
    "df.loc[missing_data, 'Product Category'] = predicted_categories\n",
    "\n",
    "print(df[['Description', 'Product Category']].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7f668b7e-4a66-4925-811b-7d81a10a6084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Clothing' 'Clothing' 'Clothing' 'Clothing' 'Clothing' 'Clothing'\n",
      " 'Clothing' 'Clothing' 'Clothing' 'Clothing']\n"
     ]
    }
   ],
   "source": [
    "print(predicted_categories[:10])  # Check first 10 predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf9b8d4-9203-4fae-b497-e576edcabf58",
   "metadata": {},
   "source": [
    "#### Creating a new column and randomly assigning a US region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "efe9dad8-fd85-494f-9664-287c7861a929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Description  Quantity       Date  UnitPrice  \\\n",
      "0          no description available         1 2023-12-26      50.00   \n",
      "1          no description available         2 2023-03-22     500.00   \n",
      "2          no description available         1 2023-10-18      25.00   \n",
      "3          no description available         3 2023-09-22      30.00   \n",
      "4          no description available         1 2023-03-03     500.00   \n",
      "...                             ...       ...        ...        ...   \n",
      "13187        hand warmer owl design         1 2023-07-19       2.10   \n",
      "13188        hand warmer union jack         2 2023-08-10       2.10   \n",
      "13189  plaster in tin circus parade         1 2023-09-12       1.65   \n",
      "13190          vintage snake ladder         2 2023-08-05       3.75   \n",
      "13191         lunch bag suki design         1 2023-05-07       1.65   \n",
      "\n",
      "       CustomerID  Total Amount  Gender  Age Product Category  US Region  \n",
      "0            25.0         50.00  Female   64           Beauty    Midwest  \n",
      "1           161.0       1000.00    Male   64           Beauty      South  \n",
      "2           191.0         25.00    Male   64           Beauty      South  \n",
      "3           218.0         90.00    Male   64           Beauty       West  \n",
      "4           220.0        500.00    Male   64           Beauty       West  \n",
      "...           ...           ...     ...  ...              ...        ...  \n",
      "13187     17259.0          2.10    Male   28         Clothing    Midwest  \n",
      "13188     17259.0          4.20  Female   44         Clothing    Midwest  \n",
      "13189     17259.0          1.65  Female   45         Clothing  Northeast  \n",
      "13190     17259.0          7.50  Female   79         Clothing    Midwest  \n",
      "13191     17259.0          1.65  Female   41         Clothing      South  \n",
      "\n",
      "[13192 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "# List of US regions\n",
    "us_regions = ['Northeast', 'Midwest', 'South', 'West']\n",
    "\n",
    "# Randomly assign a region to each row in the DataFrame\n",
    "df['US Region'] = np.random.choice(us_regions, size=len(df))\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "55bb3f35-a608-4c3d-be1a-d0de03e4770d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "df.to_csv('C:/Users/Celeste/Downloads/Target_Customer_Data.V5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3951bdae-ca42-4da9-92cf-ead4cdadd930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product Category\n",
      "Clothing       351\n",
      "Electronics    342\n",
      "Beauty         307\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4b374d-a7aa-4ebb-98bf-000e0da260c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
